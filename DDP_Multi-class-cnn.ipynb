{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d4b151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:30:29.544814Z",
     "start_time": "2022-05-16T20:30:28.852050Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import random\n",
    "from math import log10, floor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77bcd60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:30:31.401182Z",
     "start_time": "2022-05-16T20:30:31.391775Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    h,w = img.shape[:2]\n",
    "    imgs=[]\n",
    "    for i in range(0,w-224,20):\n",
    "        for j in range(0, h-224,20):\n",
    "            imgs.append(img[j:j+224, i:i+224])\n",
    "    return imgs\n",
    "\n",
    "def fill(img, h, w):\n",
    "    img = cv2.resize(img, (w, h), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "        \n",
    "def horizontal_shift(img, ratio=0.0):\n",
    "    if ratio > 1 or ratio < -1:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    h, w = img.shape\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift)]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):]  \n",
    "    img = fill(img, h, w)\n",
    "    return img\n",
    "\n",
    "def vertical_shift(img, ratio=0.0):\n",
    "    if ratio > 1 or ratio < -1:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    h, w = img.shape\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:int(h-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    return img\n",
    "\n",
    "def zoom(img, value):\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return img\n",
    "    h, w = img.shape\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken]\n",
    "    img = fill(img, h, w)\n",
    "    return img\n",
    "\n",
    "def horizontal_flip(img):\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "def vertical_flip(img):\n",
    "    return cv2.flip(img, 0)\n",
    "\n",
    "def rotation(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "    return img\n",
    "\n",
    "def highpass(img, sigma):\n",
    "    return img - cv2.GaussianBlur(img, (0,0), sigma) + 127\n",
    "\n",
    "def hist_sliding(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efe392",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Crop pics and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b51f479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:30:34.786084Z",
     "start_time": "2022-05-16T20:30:34.778617Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    ### Crop pics\n",
    "    for i in range(1,7):\n",
    "        dir_list = os.listdir(f\"Dataset2/{i}\")\n",
    "        count=0\n",
    "        for img_file in dir_list:\n",
    "            img = cv2.imread(f\"Dataset2/{i}/{img_file}\")\n",
    "            imgs = crop(img)\n",
    "\n",
    "            for k in range(len(imgs)):\n",
    "                cv2.imwrite(f\"Dataset2/{i}/{count}.jpg\", imgs[k])\n",
    "                count+=1\n",
    "\n",
    "    ### Horizontal Flip\n",
    "    for i in range(1,7):\n",
    "        dir_list = os.listdir(f\"Dataset2/{i}\")\n",
    "        n=len(dir_list)\n",
    "        print(i,end=\", \")\n",
    "        for img_file in dir_list:\n",
    "            img = cv2.imread(f\"Dataset2/{i}/{img_file}\")\n",
    "            img = horizontal_flip(img)\n",
    "            cv2.imwrite(f\"Dataset2/{i}/{n+int(img_file.split('.')[0])}.jpg\", img)\n",
    "    print()   \n",
    "    ### Vertical Flip\n",
    "    for i in range(1,7):\n",
    "        dir_list = os.listdir(f\"Dataset2/{i}\")\n",
    "        n=len(dir_list)\n",
    "        print(i, end=\", \")\n",
    "        for img_file in dir_list:\n",
    "            img = cv2.imread(f\"Dataset2/{i}/{img_file}\")\n",
    "            img = horizontal_flip(img)\n",
    "            cv2.imwrite(f\"Dataset2/{i}/{n+int(img_file.split('.')[0])}.jpg\", img)\n",
    "    print()\n",
    "    ### Rotation by 90 degree\n",
    "    for i in range(1,7):\n",
    "        dir_list = os.listdir(f\"Dataset2/{i}\")\n",
    "        n=len(dir_list)\n",
    "        print(i, end=\", \")\n",
    "        for img_file in dir_list:\n",
    "            img = cv2.imread(f\"Dataset2/{i}/{img_file}\")\n",
    "            img = horizontal_flip(img)\n",
    "            cv2.imwrite(f\"Dataset2/{i}/{n+int(img_file.split('.')[0])}.jpg\", img)\n",
    "            \n",
    "#preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fc163",
   "metadata": {},
   "source": [
    "## Models\n",
    "### CNN model for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12bee0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:30:38.523329Z",
     "start_time": "2022-05-16T20:30:38.180101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362880,) (362880,)\n"
     ]
    }
   ],
   "source": [
    "X=[]; y=[]\n",
    "for i in range(1,7):\n",
    "    dir_list = os.listdir(f\"Dataset2/{i}\")\n",
    "    for img_file in dir_list:\n",
    "        X.append(f\"Dataset2/{i}/{img_file}\")\n",
    "        y.append(i)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38a215f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:30:59.194588Z",
     "start_time": "2022-05-16T20:30:56.465127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232243,) (58061,) (72576,) (232243,) (58061,) (72576,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87acc9ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:03:55.550859Z",
     "start_time": "2022-05-16T20:33:56.828624Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(30000):\n",
    "    img = cv2.imread(X_train[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = hist_sliding(img)\n",
    "    img = highpass(img, 5)\n",
    "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    cv2.imwrite(f\"Dataset2/train/{y_train[i]}/{i}.jpg\", img)\n",
    "\n",
    "for i in range(3000):\n",
    "    img = cv2.imread(X_val[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = hist_sliding(img)\n",
    "    img = highpass(img, 5)\n",
    "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    cv2.imwrite(f\"Dataset2/val/{y_val[i]}/{i}.jpg\", img)\n",
    "\n",
    "for i in range(3000):\n",
    "    img = cv2.imread(X_test[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = hist_sliding(img)\n",
    "    img = highpass(img, 5)\n",
    "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    cv2.imwrite(f\"Dataset2/test/{y_test[i]}/{i}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c31e6c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:11:33.609691Z",
     "start_time": "2022-05-16T21:10:58.298752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 02:41:12.068052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/naveen/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-05-17 02:41:12.068095: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a new generator\n",
    "imagegen = ImageDataGenerator()\n",
    "# load train data\n",
    "train = imagegen.flow_from_directory(\"Dataset2/train\", class_mode=\"categorical\", shuffle=False, batch_size=32, target_size=(224, 224))\n",
    "val = imagegen.flow_from_directory(\"Dataset2/val/\", class_mode=\"categorical\", shuffle=False, batch_size=32, target_size=(224, 224))\n",
    "test = imagegen.flow_from_directory(\"Dataset2/test/\", class_mode=\"categorical\", shuffle=False, batch_size=32, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2a77cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T22:40:17.286321Z",
     "start_time": "2022-05-16T21:13:08.265920Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 02:43:12.637532: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-17 02:43:12.637589: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (naveen): /proc/driver/nvidia/version does not exist\n",
      "2022-05-17 02:43:12.662234: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 02:43:19.919573: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19267584 exceeds 10% of free system memory.\n",
      "2022-05-17 02:43:20.005906: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 160563200 exceeds 10% of free system memory.\n",
      "2022-05-17 02:43:20.915421: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 40140800 exceeds 10% of free system memory.\n",
      "2022-05-17 02:43:20.946427: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20070400 exceeds 10% of free system memory.\n",
      "2022-05-17 02:43:21.884031: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20815200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1107s 1s/step - loss: 0.5258 - accuracy: 0.8065 - val_loss: 4.8865 - val_accuracy: 0.3717\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1297s 1s/step - loss: 0.1208 - accuracy: 0.9704 - val_loss: 2.6420 - val_accuracy: 0.5263\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1090s 1s/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 4.0997 - val_accuracy: 0.5133\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 895s 955ms/step - loss: 0.0719 - accuracy: 0.9815 - val_loss: 6.7602 - val_accuracy: 0.5113\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 830s 885ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 11.5042 - val_accuracy: 0.4537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff900cc8670>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "\n",
    "# build a sequential model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "# fit on data for 5 epochs\n",
    "checkpoint = ModelCheckpoint('Models2/cnn{epoch:01d}.h5', save_freq=938)\n",
    "model.fit(train, epochs=5, validation_data=val, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "409bc9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T23:04:27.003410Z",
     "start_time": "2022-05-16T23:04:11.367177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1    0.59524   0.32258   0.41841       310\n",
      "           2    0.00000   0.00000   0.00000       320\n",
      "           3    0.00000   0.00000   0.00000       552\n",
      "           4    0.46154   0.66667   0.54545       612\n",
      "           5    0.34089   0.85251   0.48704       617\n",
      "           6    0.82957   0.56197   0.67004       589\n",
      "\n",
      "    accuracy                        0.45500      3000\n",
      "   macro avg    0.37121   0.40062   0.35349      3000\n",
      "weighted avg    0.38865   0.45500   0.38623      3000\n",
      "\n",
      "[[100   0   0  26 180   4]\n",
      " [  0   0   0 320   0   0]\n",
      " [  0   0   0   0 552   0]\n",
      " [  0   0   0 408 204   0]\n",
      " [ 11   0   4  12 526  64]\n",
      " [ 57   0   2 118  81 331]]\n",
      "ACCURACY OF THE MODEL:  0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveen/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/naveen/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/naveen/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "y_test = to_categorical(test.labels)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "filenames = test.filenames\n",
    "nb_samples = len(filenames)\n",
    "model = load_model(\"Models2/cnn5.h5\")\n",
    "y_pred = model.predict(test, steps=np.ceil(nb_samples/32))\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "print(classification_report(y_test, y_pred, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"], digits=5))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ACCURACY OF THE MODEL: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8be049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
